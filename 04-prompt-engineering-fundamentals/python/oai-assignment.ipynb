{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken==0.4.0 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from tiktoken==0.4.0) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from tiktoken==0.4.0) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.4.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.4.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.4.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken==0.4.0) (2024.8.30)\n",
      "Requirement already satisfied: openai==1.55.1 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (1.55.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from openai==1.55.1) (4.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from openai==1.55.1) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from openai==1.55.1) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from openai==1.55.1) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from openai==1.55.1) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from openai==1.55.1) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from openai==1.55.1) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from openai==1.55.1) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai==1.55.1) (3.7)\n",
      "Requirement already satisfied: certifi in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.55.1) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.55.1) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.55.1) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai==1.55.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai==1.55.1) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /home/ruschi/miniconda3/envs/ai4beg/lib/python3.11/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tiktoken==0.4.0\n",
    "!{sys.executable} -m pip install openai==1.55.1 \n",
    "!{sys.executable} -m pip install  python-dotenv==1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook was auto-generated by GitHub Copilot Chat and is meant for initial setup only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Prompt Engineering\n",
    "Prompt engineering is the process of designing and optimizing prompts for natural language processing tasks. It involves selecting the right prompts, tuning their parameters, and evaluating their performance. Prompt engineering is crucial for achieving high accuracy and efficiency in NLP models. In this section, we will explore the basics of prompt engineering using the OpenAI models for exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Tokenization\n",
    "Explore Tokenization using tiktoken, an open-source fast tokenizer from OpenAI\n",
    "See [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.10\n",
      "[198, 41, 20089, 374, 279, 18172, 11841, 505, 279, 8219, 323, 279, 7928, 304, 279, 25450, 744, 13, 1102, 374, 264, 6962, 14880, 449, 264, 3148, 832, 7716, 52949, 339, 430, 315, 279, 8219, 11, 719, 1403, 9976, 7561, 34902, 3115, 430, 315, 682, 279, 1023, 33975, 304, 279, 25450, 744, 11093, 13, 50789, 374, 832, 315, 279, 72021, 6302, 9621, 311, 279, 19557, 8071, 304, 279, 3814, 13180, 11, 323, 706, 1027, 3967, 311, 14154, 86569, 2533, 1603, 12715, 3925, 13, 1102, 374, 7086, 1306, 279, 13041, 10087, 50789, 8032, 777, 60, 3277, 19894, 505, 9420, 11, 50789, 649, 387, 10107, 3403, 369, 1202, 27000, 3177, 311, 6445, 9621, 35612, 17706, 508, 60, 323, 374, 389, 5578, 279, 4948, 1481, 1315, 478, 5933, 1665, 304, 279, 3814, 13180, 1306, 279, 17781, 323, 50076, 627]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'\\n',\n",
       " b'J',\n",
       " b'upiter',\n",
       " b' is',\n",
       " b' the',\n",
       " b' fifth',\n",
       " b' planet',\n",
       " b' from',\n",
       " b' the',\n",
       " b' Sun',\n",
       " b' and',\n",
       " b' the',\n",
       " b' largest',\n",
       " b' in',\n",
       " b' the',\n",
       " b' Solar',\n",
       " b' System',\n",
       " b'.',\n",
       " b' It',\n",
       " b' is',\n",
       " b' a',\n",
       " b' gas',\n",
       " b' giant',\n",
       " b' with',\n",
       " b' a',\n",
       " b' mass',\n",
       " b' one',\n",
       " b'-th',\n",
       " b'ousand',\n",
       " b'th',\n",
       " b' that',\n",
       " b' of',\n",
       " b' the',\n",
       " b' Sun',\n",
       " b',',\n",
       " b' but',\n",
       " b' two',\n",
       " b'-and',\n",
       " b'-a',\n",
       " b'-half',\n",
       " b' times',\n",
       " b' that',\n",
       " b' of',\n",
       " b' all',\n",
       " b' the',\n",
       " b' other',\n",
       " b' planets',\n",
       " b' in',\n",
       " b' the',\n",
       " b' Solar',\n",
       " b' System',\n",
       " b' combined',\n",
       " b'.',\n",
       " b' Jupiter',\n",
       " b' is',\n",
       " b' one',\n",
       " b' of',\n",
       " b' the',\n",
       " b' brightest',\n",
       " b' objects',\n",
       " b' visible',\n",
       " b' to',\n",
       " b' the',\n",
       " b' naked',\n",
       " b' eye',\n",
       " b' in',\n",
       " b' the',\n",
       " b' night',\n",
       " b' sky',\n",
       " b',',\n",
       " b' and',\n",
       " b' has',\n",
       " b' been',\n",
       " b' known',\n",
       " b' to',\n",
       " b' ancient',\n",
       " b' civilizations',\n",
       " b' since',\n",
       " b' before',\n",
       " b' recorded',\n",
       " b' history',\n",
       " b'.',\n",
       " b' It',\n",
       " b' is',\n",
       " b' named',\n",
       " b' after',\n",
       " b' the',\n",
       " b' Roman',\n",
       " b' god',\n",
       " b' Jupiter',\n",
       " b'.[',\n",
       " b'19',\n",
       " b']',\n",
       " b' When',\n",
       " b' viewed',\n",
       " b' from',\n",
       " b' Earth',\n",
       " b',',\n",
       " b' Jupiter',\n",
       " b' can',\n",
       " b' be',\n",
       " b' bright',\n",
       " b' enough',\n",
       " b' for',\n",
       " b' its',\n",
       " b' reflected',\n",
       " b' light',\n",
       " b' to',\n",
       " b' cast',\n",
       " b' visible',\n",
       " b' shadows',\n",
       " b',[',\n",
       " b'20',\n",
       " b']',\n",
       " b' and',\n",
       " b' is',\n",
       " b' on',\n",
       " b' average',\n",
       " b' the',\n",
       " b' third',\n",
       " b'-b',\n",
       " b'right',\n",
       " b'est',\n",
       " b' natural',\n",
       " b' object',\n",
       " b' in',\n",
       " b' the',\n",
       " b' night',\n",
       " b' sky',\n",
       " b' after',\n",
       " b' the',\n",
       " b' Moon',\n",
       " b' and',\n",
       " b' Venus',\n",
       " b'.\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Validate OpenAI API Key Setup\n",
    "\n",
    "Run the code below to verify that your OpenAI endpoint is set up correctly. The code just tries a simple basic prompt and validates the completion. Input `oh say can you see` should complete along the lines of `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "by the dawn's early light\n",
      "what so proudly we hailed\n",
      "at the twilight's last gleaming\n",
      "whose broad stripes and bright stars\n",
      "through the perilous fight\n",
      "o'er the ramparts we watched\n",
      "were so gallantly streaming?\n",
      "and the rockets' red glare\n",
      "the bombs bursting in air\n",
      "gave proof through the night\n",
      "that our flag was still there\n",
      "o say does that star-spangled banner yet wave\n",
      "o'er the land of the free\n",
      "and the home of the brave?\n",
      "```\n",
      "\n",
      "You're quoting the first verse of \"The Star-Spangled Banner,\" the national anthem of the United States.\n"
     ]
    }
   ],
   "source": [
    "# The OpenAI SDK was updated on Nov 8, 2023 with new guidance for migration\n",
    "# See: https://github.com/openai/openai-python/discussions/742\n",
    "\n",
    "## Updated\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(base_url=\"https://llm-proxy.imla.hs-offenburg.de\")\n",
    "\n",
    "deployment=\"LLAMA3.1-8B\"\n",
    "\n",
    "## Updated\n",
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]       \n",
    "    response = client.chat.completions.create(   \n",
    "        model=deployment,                                         \n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Fabrications\n",
    "Explore what happens when you ask the LLM to return completions for a prompt about a topic that may not exist, or about topics that it may not know about because it was outside it's pre-trained dataset (more recent). See how the response changes if you try a different prompt, or a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Lesson Title:** The Martian War of 2076: A Historical Analysis\n",
      "\n",
      "**Grade Level:** 9-12\n",
      "\n",
      "**Subject:** History, Social Studies, and Science\n",
      "\n",
      "**Time Needed:** 2 class periods (approximately 90 minutes each)\n",
      "\n",
      "**Objectives:**\n",
      "\n",
      "1. Students will understand the historical context and causes of the Martian War of 2076.\n",
      "2. Students will analyze the key events and consequences of the war.\n",
      "3. Students will evaluate the impact of the war on human society and the Martian environment.\n",
      "4. Students will develop critical thinking and problem-solving skills through discussions and debates.\n",
      "\n",
      "**Materials:**\n",
      "\n",
      "* Whiteboard and markers\n",
      "* Handouts with guided questions\n",
      "* Access to online resources (e.g., NASA, Mars Society, etc.)\n",
      "* Interactive simulations or games (optional)\n",
      "\n",
      "**Lesson Plan:**\n",
      "\n",
      "**Day 1: Introduction and Causes of the War**\n",
      "\n",
      "1. Introduction (10 minutes):\n",
      "\t* Introduce the topic of the Martian War of 2076 and ask students if they have any prior knowledge about the event.\n",
      "\t* Write down key terms and concepts on the board.\n",
      "2. Historical Context (20 minutes):\n",
      "\t* Provide a brief overview of the history of space exploration and the establishment of human settlements on Mars.\n",
      "\t* Discuss the tensions and conflicts that arose between the Martian colonies and Earth governments.\n",
      "\t* Use handouts with guided questions to facilitate discussion:\n",
      "\t\t+ What were the main reasons for the Martian colonies' desire for independence?\n",
      "\t\t+ How did Earth governments respond to the Martian colonies' demands?\n",
      "3. Causes of the War (30 minutes):\n",
      "\t* Present the key events and incidents that led to the outbreak of war:\n",
      "\t\t+ The Mars Colonies' Declaration of Independence\n",
      "\t\t+ The Earth governments' refusal to recognize Martian sovereignty\n",
      "\t\t+ The first skirmishes between Martian and Earth forces\n",
      "\t* Use interactive simulations or games to recreate the events and allow students to take on different roles (e.g., Martian colonist, Earth government official, etc.).\n",
      "\n",
      "**Day 2: Consequences and Impact**\n",
      "\n",
      "1. Key Events of the War (30 minutes):\n",
      "\t* Present the major battles and events of the war:\n",
      "\t\t+ The Battle of Olympus Mons\n",
      "\t\t+ The Martian Colonies' use of guerrilla warfare\n",
      "\t\t+ The Earth governments' deployment of advanced military technology\n",
      "\t* Use handouts with guided questions to facilitate discussion:\n",
      "\t\t+ How did the war affect the Martian environment?\n",
      "\t\t+ What were the human costs of the war?\n",
      "2. Consequences and Impact (40 minutes):\n",
      "\t* Discuss the long-term consequences of the war:\n",
      "\t\t+ The establishment of a new Martian government\n",
      "\t\t+ The impact on Earth-Mars relations\n",
      "\t\t+ The effects on the Martian environment and human settlements\n",
      "\t* Use interactive simulations or games to recreate the aftermath of the war and allow students to take on different roles (e.g., Martian government official, Earth diplomat, etc.).\n",
      "\n",
      "**Assessment:**\n",
      "\n",
      "* Participation in class discussions and debates (20 points)\n",
      "* Handouts with guided questions (20 points)\n",
      "* Interactive simulations or games (20 points)\n",
      "* Written reflection or essay (40 points)\n",
      "\n",
      "**Extension:**\n",
      "\n",
      "* Invite a guest speaker to discuss the current state of Mars exploration and settlement.\n",
      "* Have students research and present on the impact of the Martian War on different aspects of society (e.g., economy, politics, culture, etc.).\n",
      "* Create a multimedia presentation (e.g., video, podcast, etc.) on the Martian War of 2076.\n",
      "\n",
      "**Interactive Simulations or Games:**\n",
      "\n",
      "* \"Mars Colonies: A Game of Survival\" (board game or online simulation)\n",
      "* \"Earth-Mars Diplomacy\" (role-playing game or online simulation)\n",
      "* \"The Martian War: A Simulation\" (online simulation or video game)\n",
      "\n",
      "**Online Resources:**\n",
      "\n",
      "* NASA: Mars Exploration Program\n",
      "* Mars Society: Mars Colonization and Settlement\n",
      "* Space.com: Mars News and Updates\n",
      "\n",
      "**Note:** The Martian War of 2076 is a fictional event and not based on actual historical events. This lesson plan is designed to encourage critical thinking and problem-solving skills while exploring a hypothetical scenario.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Instruction Based \n",
    "Use the \"text\" variable to set the primary content \n",
    "and the \"prompt\" variable to provide an instruction related to that primary content.\n",
    "\n",
    "Here we ask the model to summarize the text for a second-grade student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's talk about Jupiter. \n",
      "\n",
      "Jupiter is a big planet in our Solar System. It's the biggest one! It's made of gas and is very heavy. If you look up at the night sky, you can see Jupiter. It's one of the brightest things you can see without a special tool. People have known about Jupiter for a very long time, even before we started writing things down. It's named after a Roman god named Jupiter.\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Complex Prompt \n",
    "Try a request that has system, user and assistant messages \n",
    "System sets assistant context\n",
    "User & Assistant messages provide multi-turn conversation context\n",
    "\n",
    "Note how the assistant personality is set to \"sarcastic\" in the system context. \n",
    "Try using a different personality context. Or try a different series of input/output messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So glad you asked, it was played in Texas (Minneapolis actually was a part of the playoffs first but) and then in Arizona due to the COVID-19 pandemic, but the final was played in Globe Life Field in Arlington, Texas.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explore Your Intuition\n",
    "The above examples give you patterns that you can use to create new prompts (simple, complex, instruction etc.) - try creating other exercises to explore some of the other ideas we've talked about like examples, cues and more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
